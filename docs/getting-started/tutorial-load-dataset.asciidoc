[[tutorial-load-dataset]]
== 加载示例数据

本节教程依赖以下数据:

* 威廉·莎士比亚全集，解析成适当的字段。点击这里下载这个数据集：
  https://download.elastic.co/demos/kibana/gettingstarted/shakespeare_6.0.json[shakespeare.json].
* 一组虚构的账户与随机生成的数据。点击这里下载这个数据集：
  https://download.elastic.co/demos/kibana/gettingstarted/accounts.zip[accounts.zip]
* 一组随机生成的日志文件。点击这里下载这个数据集：
  https://download.elastic.co/demos/kibana/gettingstarted/logs.jsonl.gz[logs.jsonl.gz]

两个数据集被压缩。使用以下命令解压缩文件：

[source,shell]
unzip accounts.zip
gunzip logs.jsonl.gz

莎士比亚数据集的组织方式如下：

[source,json]
{
    "line_id": INT,
    "play_name": "String",
    "speech_number": INT,
    "line_number": "String",
    "speaker": "String",
    "text_entry": "String",
}

帐户数据集的组织方式如下：

[source,json]
{
    "account_number": INT,
    "balance": INT,
    "firstname": "String",
    "lastname": "String",
    "age": INT,
    "gender": "M or F",
    "address": "String",
    "employer": "String",
    "email": "String",
    "city": "String",
    "state": "String"
}

日志数据集的模式有许多不同的字段，但在本教程中使用的值得注意的是：

[source,json]
{
    "memory": INT,
    "geo.coordinates": "geo_point"
    "@timestamp": "date"
}

莎士比亚和日志数据集加载之前，我们需要为字段设置 {es-ref}mapping.html[_mappings_]。
映射把索引中的文档按逻辑分组并指定了字段的属性，比如字段的可搜索性或者该字段是否_tokenized_，或分解成单独的单词。
使用以下命令在一个终端（如“bash”）建立一个莎士比亚数据集的映射：

[source,js]
PUT /shakespeare
{
 "mappings": {
  "doc": {
   "properties": {
    "speaker": {"type": "keyword"},
    "play_name": {"type": "keyword"},
    "line_id": {"type": "integer"},
    "speech_number": {"type": "integer"}
   }
  }
 }
}

//CONSOLE

这个映射指定了数据集的以下特点：

* 因为 _speaker_ 和 _play_name_ 字段是关键字字段，它们不是分析。字符串即使包含多个词也仍被视为一个整体。
* _line_id_ 和 _speech_number_ 字段是整数。

日志数据集需要一个映射，在这些字段上应用"geo_point"类型来标记纬度/经度对作为日志的地理标识。

使用下面的命令来为日志建立"geo_point"映射：

[source,js]
PUT /logstash-2015.05.18
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}

//CONSOLE

[source,js]
PUT /logstash-2015.05.19
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}

//CONSOLE

[source,js]
PUT /logstash-2015.05.20
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}

//CONSOLE

账户数据集不需要任何映射，基于这一点我们准备用 Elasticsearch {es-ref}docs-bulk.html('bulk') API 来加载数据集，命令如下：

[source,shell]
curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.json
curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/shakespeare/doc/_bulk?pretty' --data-binary @shakespeare_6.0.json
curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl

执行这些命令可能需要一段时间，这取决于可用的计算资源。
使用下面的命令来验证加载成功：

[source,js]
GET /_cat/indices?v

//CONSOLE
你应该会看到类似于下面的输出：
[source,shell]
health status index               pri rep docs.count docs.deleted store.size pri.store.size
yellow open   bank                  5   1       1000            0    418.2kb        418.2kb
yellow open   shakespeare           5   1     111396            0     17.6mb         17.6mb
yellow open   logstash-2015.05.18   5   1       4631            0     15.6mb         15.6mb
yellow open   logstash-2015.05.19   5   1       4624            0     15.7mb         15.7mb
yellow open   logstash-2015.05.20   5   1       4750            0     16.4mb         16.4mb
